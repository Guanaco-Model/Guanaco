<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Guanaco: A Multilingual Instruction-Following Language Model</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }

        h1 {
            text-align: center;
            color: #5c5c5c;
            font-size: 42px;
            margin-bottom: 20px;
            border-bottom: 2px solid #5c5c5c;
            display: inline-block;
            padding-bottom: 10px;
        }

        img {
            display: block;
            margin: 0 auto;
            width: 50%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        p {
            font-size: 18px;
            line-height: 1.6;
            color: #333;
            text-align: justify;
        }

        .credit {
            font-size: 14px;
            text-align: center;
            margin-bottom: 20px;
            color: #777;
            font-style: italic;
        }

        .highlight {
            background-color: #ffc04c;
            padding: 2px 5px;
            border-radius: 3px;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Guanaco: A Multilingual Instruction-Following Language Model Based on LLaMA 7B</h1>
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Lama_guanicoe_9012.jpg/640px-Lama_guanicoe_9012.jpg" alt="Guanaco">
        <p class="credit">Image by NobbiP (CC BY 3.0)</p>
        <p>
            Guanaco is an instruction-following language model trained on Meta's LLaMA 7B model. Building upon the original 52K data from the Alpaca model, we added an additional 54,574 entries, covering <span class="highlight">English, Simplified Chinese, Traditional Chinese (Taiwan), Traditional Chinese (Hong Kong),</span> and various linguistic and grammatical tasks. By retraining and optimizing the model with this rich data, Guanaco demonstrates excellent performance and potential in a multilingual environment.
        </p>
        <p>
            To promote openness and replicability in research, we have made the <a href="https://huggingface.co/datasets/JosephusCheung/GuanacoDataset" rel="nofollow">Guanaco Dataset</a> publicly available and plan to release the model weights in the future. By providing these resources, we hope to encourage more researchers to engage in related research and jointly advance the development of instruction-following language models.
        </p>
        <p>
            When using the Guanaco model, please note the following points:
            <br>- The Guanaco model has not yet been filtered for harmful, biased, or explicit content. During use, outputs that do not conform to ethical norms may be generated. Please pay special attention to this issue in research or practical applications.
</p>
<p>     
<span>
To-Do List:
</span>
<ul>
<li><p>Expand language support in the dataset:</p>
<p>Incorporate additional languages such as Japanese, German, and more into the dataset. This expansion should include task examples that cover advanced grammar analysis and dialogue understanding for these languages.</p>
</li>
<li><p>Create a dialogue-oriented Chatbot dataset:</p>
<p>Develop a dataset specifically designed for conversation-based applications, containing examples that facilitate the model's ability to engage in interactive and dynamic dialogues with users.</p>
</li>
<li><p>Add Toolformer-supporting tasks:</p>
<p>Introduce tasks that train the model to autonomously call external APIs using Toolformer, allowing the model to access and utilize various web services and data sources, thereby enhancing its problem-solving capabilities.</p>
</li>
<li><p>Develop tasks for rapid integration of external knowledge:</p>
<p>Design tasks that encourage the model to quickly incorporate knowledge from external sources such as search engines and artificial intelligence knowledge engines. These tasks would be particularly beneficial for smaller models with limited knowledge reserves, enabling them to efficiently utilize external information to respond to user queries.</p>
</li>
</ul> 
</div>
</p>
<hr>
    <p>The Guanaco model is designed to work well with instruction-following question-answering tasks and continuous conversations. For standard instruction-following QA tasks, use the following template:</p>
    <pre><code>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Input:
{input}

### Response:
</code></pre>
    <p>For continuous conversations, adopt the following strategy:</p>
    <ol>
        <li>Maintain a conversation context window of adjustable length within the Instruction, containing past dialogue records. The dialogue roles are User (for the person asking questions) and Assistant (for the one providing answers).</li>
        <li>The Input is divided into two parts:
            <ol type="a">
                <li>The System role provides factual information. This information can come from web search data, full-text search or vector search engines, or other knowledge APIs.</li>
                <li>The User role includes the new question in the ongoing conversation.</li>
            </ol>
        </li>
        <li>In the Response, the Assistant role answers the question by:
            <ol type="a">
                <li>Adhering to the context provided in the Instruction.</li>
                <li>Strictly following the guidance of the System role to provide accurate information.</li>
                <li>Responding to the User's new question from the Input.</li>
            </ol>
        </li>
    </ol>
    <p>This approach yields better performance on small models compared to using embedded span toolformer structures.</p>
</body>
</html>
