
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Guanaco - Generative Universal Assistant for Natural-language Adaptive Context-aware Omnilingual outputs</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }

        h1 {
            text-align: center;
            color: #5c5c5c;
            font-size: 42px;
            margin-bottom: 20px;
            border-bottom: 2px solid #5c5c5c;
            display: inline-block;
            padding-bottom: 10px;
            font-weight: normal;
        }

        img {
            display: block;
            margin: 0 auto;
            width: 50%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        p {
            font-size: 18px;
            line-height: 1.6;
            color: #333;
            text-align: justify;
        }

        .credit {
            font-size: 14px;
            text-align: center;
            margin-bottom: 20px;
            color: #777;
            font-style: italic;
        }

        .highlight {
            background-color: #ffc04c;
            padding: 2px 5px;
            border-radius: 3px;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1><b>Guanaco</b> - <b>G</b>enerative <b>U</b>niversal <b>A</b>ssistant for <b>N</b>atural-language <b>A</b>daptive <b>C</b>ontext-aware <b>O</b>mnilingual outputs</h1>
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Lama_guanicoe_9012.jpg/640px-Lama_guanicoe_9012.jpg" alt="Guanaco">
        <p class="credit">Image by NobbiP (CC BY 3.0)</p>


        <section>

            <h2><b>Our new work:</b>  <span class="highlight"><a href="https://huggingface.co/CausalLM/14B">CausalLM</a></span> 14B & 7B, SOTA model of its size, outperforming 70B models.</h2>
            
            <p><b>Recent update:</b> Added support for <span class="highlight">multimodal VQA</span>.</p>

            <p>Guanaco is an advanced instruction-following language model built on Meta's LLaMA 7B model. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 entries have been incorporated, covering <span class="highlight">English, Simplified Chinese, Traditional Chinese (Taiwan), Traditional Chinese (Hong Kong), Japanese, Deutsch</span>, and various linguistic and grammatical tasks. This wealth of data enables Guanaco to perform exceptionally well in multilingual environments.</p>
    
            <p>In an effort to foster openness and replicability in research, we have made the <a href="https://huggingface.co/datasets/JosephusCheung/GuanacoDataset">Guanaco Dataset</a> publicly accessible and released the <a href="https://huggingface.co/JosephusCheung/Guanaco">model weights</a>. By providing these resources, we aim to inspire more researchers to pursue related research and collectively advance the development of instruction-following language models.</p>
    
            <p>When utilizing the Guanaco model, please bear in mind the following points:</p>
    
            <ul>
                <li>The Guanaco model has not been filtered for harmful, biased, or explicit content. As a result, outputs that do not adhere to ethical norms may be generated during use. Please exercise caution when using the model in research or practical applications.</li>
            </ul>
    
            <h2>1. Improved context and prompt role support:</h2>
            <p>The new format is designed to be similar to ChatGPT, allowing for better integration with the Alpaca format and enhancing the overall user experience.</p>
    
            <p>Instruction is utilized as a few-shot context to support diverse inputs and responses, making it easier for the model to understand and provide accurate responses to user queries.</p>
    
            <p>The format is as follows:</p>
    
            <pre>
    ### Instruction:
    User: History User Input
    Assistant: History Assistant Answer
    ### Input:
    System: Knowledge
    User: New User Input
    ### Response:
    New Assistant Answer
            </pre>
    
            <p>This structured format allows for easier tracking of the conversation history and maintaining context throughout a multi-turn dialogue.</p>
    
            <h2>2. Role-playing support:</h2>
           
            <p>Guanaco now offers advanced role-playing support, similar to Character.AI, in English, Simplified Chinese, Traditional Chinese, Japanese, and Deutsch, making it more versatile for users from different linguistic backgrounds.</p>
    
            <p>Users can instruct the model to assume specific roles, historical figures, or fictional characters, as well as personalities based on their input. This allows for more engaging and immersive conversations.</p>
    
            <p>The model can use various sources of information to provide knowledge and context for the character's background and behavior, such as encyclopedic entries, first-person narrations, or a list of personality traits.</p>
    
            <p>The model will consistently output responses in the format "Character Name: Reply" to maintain the chosen role throughout the conversation, enhancing the user's experience.</p>
    
            <h2>3. Rejection of answers and avoidance of erroneous responses:</h2>
            <p>The model has been updated to handle situations where it lacks sufficient knowledge or is unable to provide a valid response more effectively.</p>
    
            <p>Reserved keywords have been introduced to indicate different scenarios and provide clearer communication with the user:</p>
    
            <ul>
                <li>NO IDEA: Indicates that the model lacks the necessary knowledge to provide an accurate answer, and will explain this to the user, encouraging them to seek alternative sources.</li>
                <li>FORBIDDEN: Indicates that the model refuses to answer due to specific reasons (e.g., legal, ethical, or safety concerns), which will be inferred based on the context of the query.</li>
                <li>SFW: Indicates that the model refuses to answer a question because it has been filtered for NSFW content, ensuring a safer and more appropriate user experience.</li>
            </ul>
    
            <h2>4. Continuation of responses for ongoing topics:</h2>
            <p>The Guanaco model can now continue answering questions or discussing topics upon the user's request, making it more adaptable and better suited for extended conversations.</p>
    
            <p>The contextual structure consisting of System, Assistant, and User roles allows the model to engage in multi-turn dialogues, maintain context-aware conversations, and provide more coherent responses.</p>
    
            <p>The model can now accommodate role specification and character settings, providing a more immersive and tailored conversational experience based on the user's preferences.</p>
    
            <p>It is important to remember that Guanaco is a 7B-parameter model, and any knowledge-based content should be considered potentially inaccurate. We strongly recommend providing verifiable sources, such as Wikipedia, for knowledge-based answers. In the absence of sources, it is crucial to inform users of this limitation to prevent the dissemination of false information and to maintain transparency.</p>

            <h2>5. Multimodal Visual Question Answering (VQA) Support:</h2>
            <p>Guanaco expands its capabilities into the realm of multimodal interactions, now offering support for Visual Question Answering (VQA). The model achieves this by integrating data from the blip2-flan-t5-xxl for multilingual VQA tasks, marking a significant milestone in the development of multimodal chatbots.</p>

            <p>This new feature allows the model to interpret and respond to queries that involve both text and visual inputs, providing a richer, more interactive, and comprehensive user experience. Users can now ask questions about an image, and the model will analyze the visual content in conjunction with the textual query to provide a response.</p>

            <p>A noteworthy addition is the <a href="https://huggingface.co/datasets/JosephusCheung/GuanacoVQADataset">Guanaco VQA Dataset</a>, publicly accessible now.</p>

            <p>Now as a multimodal chatbot, Guanaco can bridge the gap between visual and linguistic understanding, making it an incredibly versatile tool for a wide array of applications.</p>

            <p>However, as always, we encourage responsible and ethical use of this model. Please note that while Guanaco strives to provide accurate and helpful responses, it is still crucial to cross-verify the information from reliable sources for knowledge-based queries.</p>
        </section>
</div>
</body>
</html>
